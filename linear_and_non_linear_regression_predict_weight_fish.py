# -*- coding: utf-8 -*-
"""Linear_AND_Non-Linear_regression_predict_weight_fish

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qBYtGCq4fO7muxshoUaTjBYUMHuCh9F7
"""

!gdown 10abEfTSrWVzR6D24mdhbwACf3LDYltY7

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

"""#1.Load Data"""

df = pd.read_csv('./Fish.csv')
df

df.info()

"""**One hot encoding**"""

df

encode_species = pd.get_dummies(df.Species)
encode_species.head(10)

"""**Label Encoding**"""

df["Species"] = df["Species"].astype('category')
label_ecnoding_species = df["Species"].cat.codes
label_ecnoding_species

new_df = pd.concat([df, encode_species], axis='columns')
new_df

X = new_df[[
    'VerticalLen', 'DiagonalLen', 'CrossLen', 'Height', 'Width',
    'Bream', 'Parkki', 'Perch', 'Pike', 'Roach', 'Smelt', 'Whitefish'
]]
y = new_df['Weight']

X = X.values
y = y.values

X

X_data = np.hstack((np.ones((X.shape[0], 1)), X))
X_data

X_train, X_test, y_train, y_test = train_test_split(X_data, y, test_size=0.2, random_state=42)
print('X_train shape: ', X_train.shape)
print('X_test shape: ', X_test.shape)
print('y_train shape: ', y_train.shape)
print('y_train shape: ', y_test.shape)

"""#Linear Regression"""

def r2score(y_pred, y):
    rss = np.sum((y_pred - y) ** 2)
    tss = np.sum((y-y.mean()) ** 2)

    r2 = 1 - (rss / tss)
    return r2

class LinearRegression:
    def __init__(self, X_data, y_target, learning_rate=0.00001, num_epochs=10000):
        self.X_data = X_data
        self.y_target = y_target
        self.learning_rate = learning_rate
        self.num_epochs = num_epochs
        self.num_samples = self.X_data.shape[0]

        # Initial Coefficients
        self.theta = np.random.randn(self.X_data.shape[1])
        self.losses = []

    def compute_loss(self, y_pred, y_target):
        loss = (y_pred-y_target)*(y_pred-y_target)
        loss = np.mean(loss)
        return loss

    def predict(self, X_data):
        y_pred = X_data.dot(self.theta)
        return y_pred

    def fit(self):
        for epoch in range(self.num_epochs):
            # predict
            y_pred = self.predict(self.X_data)

            # compute loss
            loss = self.compute_loss(y_pred, self.y_target)
            self.losses.append(loss)

            # compute gradient
            k = 2*(y_pred-self.y_target)
            gradients = self.X_data.T.dot(k)/self.num_samples

            # update weight
            self.theta = self.theta - self.learning_rate*gradients

            print(f'Epoch: {epoch} - Loss: {loss}')

        return {
            'loss': sum(self.losses)/len(self.losses),
            'weight': self.theta
        }

X_train

linear_model = LinearRegression(X_train, y_train, learning_rate=0.00001, num_epochs=1000)
linear_model.fit()

preds = linear_model.predict(X_train)
r2score(preds, y_train)

preds = linear_model.predict(X_test)
r2score(preds, y_test)

"""#Polynomial Regression

##Simple Approach
**Form**
$(a+b)^2 => a^2 + b^2 + a + b + 1$
"""

def create_polynomial_features(X, degree=2):
    """Creates the polynomial features
    Args:
        X: A array for the data.
        degree: A intege for the degree of
        the generated polynomial function.
    """
    X_mem = []
    for X_sub in X.T:
        X_sub = X_sub.T
        X_new = X_sub
        for d in range(2, degree+1):
            X_new = np.c_[X_new, np.power(X_sub, d)]
        X_mem.extend(X_new.T)
    return np.c_[X_mem].T

X_new = np.array([[1, 2], [3, 4]])
X_new

create_polynomial_features(X_new, degree=2)

create_polynomial_features(X_new, degree=3)

X.shape

X_poly = create_polynomial_features(X, degree=2)
X_poly

X_poly.shape

X_data = np.hstack((np.ones((X_poly.shape[0], 1)), X_poly))
X_data

X_data.shape, y.shape

X_train, X_test, y_train, y_test = train_test_split(X_data, y, test_size=0.2, random_state=42)
print('X_train shape: ', X_train.shape)
print('X_test shape: ', X_test.shape)
print('y_train shape: ', y_train.shape)
print('y_train shape: ', y_test.shape)

poly_model = LinearRegression(X_train, y_train, learning_rate=0.0000001, num_epochs=100000)
poly_model.fit()

preds = poly_model.predict(X_train)
r2score(preds, y_train)

preds = poly_model.predict(X_test)
r2score(preds, y_test)

"""## **Sklearn**"""

X.shape

y.shape

from sklearn.preprocessing import PolynomialFeatures

poly_features = PolynomialFeatures(degree=2)

X_data = poly_features.fit_transform(X)
X_data

X_data.shape

X_train, X_test, y_train, y_test = train_test_split(X_data, y, test_size=0.2, random_state=42)
print('X_train shape: ', X_train.shape)
print('X_test shape: ', X_test.shape)
print('y_train shape: ', y_train.shape)
print('y_train shape: ', y_test.shape)

poly_model = LinearRegression(X_train, y_train, learning_rate=0.0000001, num_epochs=100000)
poly_model.fit()

preds = poly_model.predict(X_train)
r2score(preds, y_train)

preds_test = poly_model.predict(X_test)
r2score(preds_test, y_test)

